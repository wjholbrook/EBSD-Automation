{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GREEN\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\measure\\_regionprops.py:250: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n",
      "C:\\Users\\GREEN\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\measure\\_regionprops.py:260: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code performs grain size distribution analysis and dumps results into a csv file.\n",
    "Step 1: Read image and define pixel size (if needed to convert results into microns, not pixels)\n",
    "Step 2: Denoising, if required and threshold image to separate grains from boundaries.\n",
    "Step 3: Clean up image, if needed (erode, etc.) and create a mask for grains\n",
    "Step 4: Label grains in the masked image\n",
    "Step 5: Measure the properties of each grain (object)\n",
    "Step 6: Output results into a csv file\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure, color, io\n",
    "\n",
    "#STEP1 - Read image and define pixel size\n",
    "img = cv2.imread(\"images/Extrusion A.jpg\", 0)\n",
    "\n",
    "pixels_to_um = 0.5 # (1 px = 500 nm)\n",
    "\n",
    "#cropped_img = img[0:450, :]   #Crop the scalebar region\n",
    "\n",
    "#Step 2: Denoising, if required and threshold image\n",
    "\n",
    "#No need for any denoising or smoothing as the image looks good.\n",
    "#Otherwise, try Median or NLM\n",
    "#plt.hist(img.flat, bins=100, range=(0,255))\n",
    "\n",
    "#Change the grey image to binary by thresholding. \n",
    "ret, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#print(ret)  #Gives 157 on grains2.jpg. OTSU determined this to be the best threshold. \n",
    "\n",
    "#View the thresh image. Some boundaries are ambiguous / faint.\n",
    "#Some pixles in the middle. \n",
    "#Need to perform morphological operations to enhance.\n",
    "\n",
    "#Step 3: Clean up image, if needed (erode, etc.) and create a mask for grains\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8) \n",
    "eroded = cv2.erode(thresh,kernel,iterations = 1)\n",
    "dilated = cv2.dilate(eroded,kernel,iterations = 1)\n",
    "\n",
    "# Now, we need to apply threshold, meaning convert uint8 image to boolean.\n",
    "mask = dilated == 255  #Sets TRUE for all 255 valued pixels and FALSE for 0\n",
    "#print(mask)   #Just to confirm the image is not inverted. \n",
    "\n",
    "#from skimage.segmentation import clear_border\n",
    "#mask = clear_border(mask)   #Removes edge touching grains. \n",
    "\n",
    "io.imshow(mask)  #cv2.imshow() not working on boolean arrays so using io\n",
    "#io.imshow(mask[250:280, 250:280])   #Zoom in to see pixelated binary image\n",
    "\n",
    "#Step 4: Label grains in the masked image\n",
    "\n",
    "#Now we have well separated grains and background. Each grain is like an object.\n",
    "#The scipy ndimage package has a function 'label' that will number each object with a unique ID.\n",
    "\n",
    "#The 'structure' parameter defines the connectivity for the labeling. \n",
    "#This specifies when to consider a pixel to be connected to another nearby pixel, \n",
    "#i.e. to be part of the same object.\n",
    "\n",
    "#use 8-connectivity, diagonal pixels will be included as part of a structure\n",
    "#this is ImageJ default but we have to specify this for Python, or 4-connectivity will be used\n",
    "# 4 connectivity would be [[0,1,0],[1,1,1],[0,1,0]]\n",
    "s = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "#label_im, nb_labels = ndimage.label(mask)\n",
    "labeled_mask, num_labels = ndimage.label(mask, structure=s)\n",
    "\n",
    "#The function outputs a new image that contains a different integer label \n",
    "#for each object, and also the number of objects found.\n",
    "\n",
    "\n",
    "#Let's color the labels to see the effect\n",
    "img2 = color.label2rgb(labeled_mask, bg_label=0)\n",
    "\n",
    "cv2.imshow('Colored Grains', img2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#View just by making mask=threshold and also mask = dilation (after morph operations)\n",
    "#Some grains are well separated after morph operations\n",
    "\n",
    "#Now each object had a unique number in the image. \n",
    "#Total number of labels found are...\n",
    "#print(num_labels) \n",
    "\n",
    "#Step 5: Measure the properties of each grain (object)\n",
    "\n",
    "# regionprops function in skimage measure module calculates useful parameters for each object.\n",
    "\n",
    "clusters = measure.regionprops(labeled_mask, img)  #send in original image for Intensity measurements\n",
    "\n",
    "#The output of the function is a list of object properties. \n",
    "\n",
    "#Test a few measurements\n",
    "#print(clusters[0].perimeter)\n",
    "\n",
    "#Can print various parameters for all objects\n",
    "#for prop in clusters:\n",
    "#    print('Label: {} Area: {}'.format(prop.label, prop.area))\n",
    "    \n",
    "#Step 6: Output results into a csv file   \n",
    "#Best way is to output all properties to a csv file\n",
    "    \n",
    "propList = ['Area',\n",
    "            'equivalent_diameter', #Added... verify if it works\n",
    "            'orientation', #Added, verify if it works. Angle btwn x-axis and major axis.\n",
    "            'MajorAxisLength',\n",
    "            'MinorAxisLength',\n",
    "            'Perimeter',\n",
    "            'MinIntensity',\n",
    "            'MeanIntensity',\n",
    "            'MaxIntensity']    \n",
    "    \n",
    "\n",
    "output_file = open('image_measurements.csv', 'w')\n",
    "output_file.write(',' + \",\".join(propList) + '\\n') #join strings in array by commas, leave first cell blank\n",
    "#First cell blank to leave room for header (column names)\n",
    "\n",
    "for cluster_props in clusters:\n",
    "    #output cluster properties to the excel file\n",
    "    output_file.write(str(cluster_props['Label']))\n",
    "    for i,prop in enumerate(propList):\n",
    "        if(prop == 'Area'): \n",
    "            to_print = cluster_props[prop]*pixels_to_um**2   #Convert pixel square to um square\n",
    "        elif(prop == 'orientation'): \n",
    "            to_print = cluster_props[prop]*57.2958  #Convert to degrees from radians\n",
    "        elif(prop.find('Intensity') < 0):          # Any prop without Intensity in its name\n",
    "            to_print = cluster_props[prop]*pixels_to_um\n",
    "        else: \n",
    "            to_print = cluster_props[prop]     #Reamining props, basically the ones with Intensity in its name\n",
    "        output_file.write(',' + str(to_print))\n",
    "    output_file.write('\\n')\n",
    "output_file.close()   #Closes the file, otherwise it would be read only. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e8798d8ef3c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"images/grains2.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html\n",
    "This code performs grain size distribution analysis and dumps results into a csv file.\n",
    "It uses watershed segmentation for better segmentation.\n",
    "Compare results to regular segmentation. \n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure, color, io\n",
    "\n",
    "img1 = cv2.imread(\"images/grains2.jpg\")\n",
    "img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "pixels_to_um = 0.5 # 1 pixel = 500 nm (got this from the metadata of original image)\n",
    "\n",
    "#Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
    "ret1, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "# Morphological operations to remove small noise - opening\n",
    "#To remove holes we can use closing\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "from skimage.segmentation import clear_border\n",
    "opening = clear_border(opening) #Remove edge touching grains\n",
    "#Check the total regions found before and after applying this. \n",
    "\n",
    "\n",
    "#Now we know that the regions at the center of cells is for sure cells\n",
    "#The region far away is background.\n",
    "#We need to extract sure regions. For that we can use erode. \n",
    "#But we have cells touching, so erode alone will not work. \n",
    "#To separate touching objects, the best approach would be distance transform and then thresholding.\n",
    "\n",
    "# let us start by identifying sure background area\n",
    "# dilating pixes a few times increases cell boundary to background. \n",
    "# This way whatever is remaining for sure will be background. \n",
    "#The area in between sure background and foreground is our ambiguous area. \n",
    "#Watershed should find this area for us. \n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=2)\n",
    "\n",
    "\n",
    "# Finding sure foreground area using distance transform and thresholding\n",
    "#intensities of the points inside the foreground regions are changed to \n",
    "#distance their respective distances from the closest 0 value (boundary).\n",
    "#https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
    "\n",
    "#Let us threshold the dist transform by 20% its max value.\n",
    "#print(dist_transform.max()) gives about 21.9\n",
    "ret2, sure_fg = cv2.threshold(dist_transform,0.2*dist_transform.max(),255,0)\n",
    "\n",
    "#0.2* max value seems to separate the cells well.\n",
    "#High value like 0.5 will not recognize some grain boundaries.\n",
    "\n",
    "# Unknown ambiguous region is nothing but bkground - foreground\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "#Now we create a marker and label the regions inside. \n",
    "# For sure regions, both foreground and background will be labeled with positive numbers.\n",
    "# Unknown regions will be labeled 0. \n",
    "#For markers let us use ConnectedComponents. \n",
    "ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "#One problem rightnow is that the entire background pixels is given value 0.\n",
    "#This means watershed considers this region as unknown.\n",
    "#So let us add 10 to all labels so that sure background is not 0, but 10\n",
    "markers = markers+10\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "#plt.imshow(markers, cmap='jet')   #Look at the 3 distinct regions.\n",
    "\n",
    "#Now we are ready for watershed filling. \n",
    "markers = cv2.watershed(img1,markers)\n",
    "#The boundary region will be marked -1\n",
    "#https://docs.opencv.org/3.3.1/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1\n",
    "\n",
    "\n",
    "#Let us color boundaries in yellow. OpenCv assigns boundaries to -1 after watershed.\n",
    "img1[markers == -1] = [0,255,255]  \n",
    "\n",
    "img2 = color.label2rgb(markers, bg_label=0)\n",
    "\n",
    "cv2.imshow('Overlay on original image', img1)\n",
    "cv2.imshow('Colored Grains', img2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Now, time to extract properties of detected cells\n",
    "# regionprops function in skimage measure module calculates useful parameters for each object.\n",
    "regions = measure.regionprops(markers, intensity_image=img)\n",
    "\n",
    "#Can print various parameters for all objects\n",
    "#for prop in regions:\n",
    "#    print('Label: {} Area: {}'.format(prop.label, prop.area))\n",
    "\n",
    "#Best way is to output all properties to a csv file\n",
    "#Let us pick which ones we want to export. \n",
    "\n",
    "propList = ['Area',\n",
    "            'equivalent_diameter', #Added... verify if it works\n",
    "            'orientation', #Added, verify if it works. Angle btwn x-axis and major axis.\n",
    "            'MajorAxisLength',\n",
    "            'MinorAxisLength',\n",
    "            'Perimeter',\n",
    "            'MinIntensity',\n",
    "            'MeanIntensity',\n",
    "            'MaxIntensity']    \n",
    "    \n",
    "\n",
    "output_file = open('image_measurements.csv', 'w')\n",
    "output_file.write('Grain #' + \",\" + \",\" + \",\".join(propList) + '\\n') #join strings in array by commas, \n",
    "#First cell to print grain number\n",
    "#Second cell blank as we will not print Label column\n",
    "\n",
    "grain_number = 1\n",
    "for region_props in regions:\n",
    "    output_file.write(str(grain_number) + ',')\n",
    "    #output cluster properties to the excel file\n",
    "#    output_file.write(str(region_props['Label']))\n",
    "    for i,prop in enumerate(propList):\n",
    "        if(prop == 'Area'): \n",
    "            to_print = region_props[prop]*pixels_to_um**2   #Convert pixel square to um square\n",
    "        elif(prop == 'orientation'): \n",
    "            to_print = region_props[prop]*57.2958  #Convert to degrees from radians\n",
    "        elif(prop.find('Intensity') < 0):          # Any prop without Intensity in its name\n",
    "            to_print = region_props[prop]*pixels_to_um\n",
    "        else: \n",
    "            to_print = region_props[prop]     #Reamining props, basically the ones with Intensity in its name\n",
    "        output_file.write(',' + str(to_print))\n",
    "    output_file.write('\\n')\n",
    "    grain_number += 1\n",
    "    \n",
    "output_file.close()   #Closes the file, otherwise it would be read only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
